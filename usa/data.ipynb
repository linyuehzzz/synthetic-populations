{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Synthetic Data Generator**\n",
    "\n",
    "Reproducible code to generate synthetic individual-level population data in the United States."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process census tables\n",
    "\n",
    "The synthetic data is generated based soly on publicly available census tables from the 2010 United States Census Summary File 1. We here read and preprocess these tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename_nhgis = \"data/nhgis0003_ds172_2010_blck_grp.csv\"\n",
    "\n",
    "## P1: TOTAL POPULATION\n",
    "data_nhgis = pd.read_csv(filename_nhgis, encoding=\"ISO-8859-1\")\n",
    "data_nhgis[\"STATEA\"] = data_nhgis[\"GISJOIN\"].str.slice(1, 3)\n",
    "data_nhgis[\"COUNTYA\"] = data_nhgis[\"GISJOIN\"].str.slice(4, 7)\n",
    "data_nhgis[\"TRACTA\"] = data_nhgis[\"GISJOIN\"].str.slice(8, 14)\n",
    "data_nhgis[\"BLKGRPA\"] = data_nhgis[\"GISJOIN\"].str.slice(14, 15)\n",
    "data_nhgis[\"GEOID10\"] = data_nhgis[[\"STATEA\", \"COUNTYA\", \"TRACTA\", \"BLKGRPA\"]].apply(lambda x: \"\".join(x), axis=1)\n",
    "\n",
    "data_geog = data_nhgis[[\"STUSAB\", \"REGIONA\", \"DIVISIONA\", \"STATE\", \"STATEA\", \"COUNTYA\", \"TRACTA\", \"BLKGRPA\", \"GEOID10\"]]\n",
    "\n",
    "## P1: TOTAL POPULATION\n",
    "data_p1 = data_nhgis[[\"H7V001\"]]\n",
    "\n",
    "## P5: HISPANIC OR LATINO ORIGIN BY RACE\n",
    "data_p5 = data_nhgis[[\"H7Z003\", \"H7Z004\", \"H7Z005\", \"H7Z006\", \"H7Z007\", \"H7Z008\", \"H7Z009\", \"H7Z011\", \"H7Z012\", \"H7Z013\", \"H7Z014\", \"H7Z015\", \"H7Z016\", \"H7Z017\"]]\n",
    "\n",
    "## P12A: SEX BY AGE (WHITE ALONE)\n",
    "data_p12A = pd.DataFrame()\n",
    "data_p12A[\"H9A00A\"] = sum([data_nhgis[\"H9A0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(3, 7)])\n",
    "data_p12A[\"H9A00B\"] = sum([data_nhgis[\"H9A0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(7, 20)])\n",
    "data_p12A[\"H9A00C\"] = sum([data_nhgis[\"H9A0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(20, 26)])\n",
    "data_p12A[\"H9A00D\"] = sum([data_nhgis[\"H9A0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(27, 31)])\n",
    "data_p12A[\"H9A00E\"] = sum([data_nhgis[\"H9A0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(31, 44)])\n",
    "data_p12A[\"H9A00F\"] = sum([data_nhgis[\"H9A0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(44, 50)])\n",
    "\n",
    "## P12B: SEX BY AGE (Black or African American Alone)\n",
    "data_p12B = pd.DataFrame()\n",
    "data_p12B[\"H9B00A\"] = sum([data_nhgis[\"H9B0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(3, 7)])\n",
    "data_p12B[\"H9B00B\"] = sum([data_nhgis[\"H9B0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(7, 20)])\n",
    "data_p12B[\"H9B00C\"] = sum([data_nhgis[\"H9B0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(20, 26)])\n",
    "data_p12B[\"H9B00D\"] = sum([data_nhgis[\"H9B0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(27, 31)])\n",
    "data_p12B[\"H9B00E\"] = sum([data_nhgis[\"H9B0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(31, 44)])\n",
    "data_p12B[\"H9B00F\"] = sum([data_nhgis[\"H9B0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(44, 50)])\n",
    "\n",
    "## P12C: Sex by Age (American Indian and Alaska Native Alone)\n",
    "data_p12C = pd.DataFrame()\n",
    "data_p12C[\"H9C00A\"] = sum([data_nhgis[\"H9C0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(3, 7)])\n",
    "data_p12C[\"H9C00B\"] = sum([data_nhgis[\"H9C0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(7, 20)])\n",
    "data_p12C[\"H9C00C\"] = sum([data_nhgis[\"H9C0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(20, 26)])\n",
    "data_p12C[\"H9C00D\"] = sum([data_nhgis[\"H9C0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(27, 31)])\n",
    "data_p12C[\"H9C00E\"] = sum([data_nhgis[\"H9C0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(31, 44)])\n",
    "data_p12C[\"H9C00F\"] = sum([data_nhgis[\"H9C0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(44, 50)])\n",
    "\n",
    "## P12D: Sex by Age (Asian Alone)\n",
    "data_p12D = pd.DataFrame()\n",
    "data_p12D[\"H9D00A\"] = sum([data_nhgis[\"H9D0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(3, 7)])\n",
    "data_p12D[\"H9D00B\"] = sum([data_nhgis[\"H9D0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(7, 20)])\n",
    "data_p12D[\"H9D00C\"] = sum([data_nhgis[\"H9D0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(20, 26)])\n",
    "data_p12D[\"H9D00D\"] = sum([data_nhgis[\"H9D0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(27, 31)])\n",
    "data_p12D[\"H9D00E\"] = sum([data_nhgis[\"H9D0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(31, 44)])\n",
    "data_p12D[\"H9D00F\"] = sum([data_nhgis[\"H9D0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(44, 50)])\n",
    "\n",
    "## P12E: Sex by Age (Native Hawaiian and Other Pacific Islander Alone)\n",
    "data_p12E = pd.DataFrame()\n",
    "data_p12E[\"H9E00A\"] = sum([data_nhgis[\"H9E0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(3, 7)])\n",
    "data_p12E[\"H9E00B\"] = sum([data_nhgis[\"H9E0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(7, 20)])\n",
    "data_p12E[\"H9E00C\"] = sum([data_nhgis[\"H9E0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(20, 26)])\n",
    "data_p12E[\"H9E00D\"] = sum([data_nhgis[\"H9E0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(27, 31)])\n",
    "data_p12E[\"H9E00E\"] = sum([data_nhgis[\"H9E0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(31, 44)])\n",
    "data_p12E[\"H9E00F\"] = sum([data_nhgis[\"H9E0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(44, 50)])\n",
    "\n",
    "## P12F: Sex by Age Sex by Age (Some Other Race Alone)\n",
    "data_p12F = pd.DataFrame()\n",
    "data_p12F[\"H9F00A\"] = sum([data_nhgis[\"H9F0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(3, 7)])\n",
    "data_p12F[\"H9F00B\"] = sum([data_nhgis[\"H9F0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(7, 20)])\n",
    "data_p12F[\"H9F00C\"] = sum([data_nhgis[\"H9F0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(20, 26)])\n",
    "data_p12F[\"H9F00D\"] = sum([data_nhgis[\"H9F0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(27, 31)])\n",
    "data_p12F[\"H9F00E\"] = sum([data_nhgis[\"H9F0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(31, 44)])\n",
    "data_p12F[\"H9F00F\"] = sum([data_nhgis[\"H9F0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(44, 50)])\n",
    "\n",
    "## P12G: Sex by Age (Two or More Races)\n",
    "data_p12G = pd.DataFrame()\n",
    "data_p12G[\"H9G00A\"] = sum([data_nhgis[\"H9G0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(3, 7)])\n",
    "data_p12G[\"H9G00B\"] = sum([data_nhgis[\"H9G0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(7, 20)])\n",
    "data_p12G[\"H9G00C\"] = sum([data_nhgis[\"H9G0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(20, 26)])\n",
    "data_p12G[\"H9G00D\"] = sum([data_nhgis[\"H9G0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(27, 31)])\n",
    "data_p12G[\"H9G00E\"] = sum([data_nhgis[\"H9G0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(31, 44)])\n",
    "data_p12G[\"H9G00F\"] = sum([data_nhgis[\"H9G0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(44, 50)])\n",
    "\n",
    "## P12H: Sex by Age (Hispanic or Latino)\n",
    "data_p12H = pd.DataFrame()\n",
    "data_p12H[\"H10H00A\"] = sum([data_nhgis[\"H9H0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(3, 7)])\n",
    "data_p12H[\"H10H00B\"] = sum([data_nhgis[\"H9H0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(7, 20)])\n",
    "data_p12H[\"H10H00C\"] = sum([data_nhgis[\"H9H0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(20, 26)])\n",
    "data_p12H[\"H10H00D\"] = sum([data_nhgis[\"H9H0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(27, 31)])\n",
    "data_p12H[\"H10H00E\"] = sum([data_nhgis[\"H9H0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(31, 44)])\n",
    "data_p12H[\"H10H00F\"] = sum([data_nhgis[\"H9H0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(44, 50)])\n",
    "\n",
    "## P12I: Sex by Age (White Alone, Not Hispanic or Latino)\n",
    "data_p12I = pd.DataFrame()\n",
    "data_p12I[\"H11I00A\"] = sum([data_nhgis[\"H9I0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(3, 7)])\n",
    "data_p12I[\"H11I00B\"] = sum([data_nhgis[\"H9I0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(7, 20)])\n",
    "data_p12I[\"H11I00C\"] = sum([data_nhgis[\"H9I0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(20, 26)])\n",
    "data_p12I[\"H11I00D\"] = sum([data_nhgis[\"H9I0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(27, 31)])\n",
    "data_p12I[\"H11I00E\"] = sum([data_nhgis[\"H9I0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(31, 44)])\n",
    "data_p12I[\"H11I00F\"] = sum([data_nhgis[\"H9I0%s\" % '{number:0{width}d}'.format(width=2, number=i)] for i in range(44, 50)])\n",
    "\n",
    "## P43: GROUP QUARTERS POPULATION BY SEX BY AGE BY GROUP QUARTERS TYPE\n",
    "data_p43 = data_nhgis[[\"H81004\", \"H81009\", \"H81014\", \"H81019\", \"H81024\", \"H81029\", \"H81035\", \"H81040\", \"H81045\", \"H81050\", \"H81055\", \"H81060\"]]\n",
    "\n",
    "cons = pd.concat([data_geog, data_p1, data_p5, data_p43, data_p12A, data_p12B, data_p12C, data_p12D, data_p12E, data_p12F, data_p12G, data_p12H, data_p12I], axis=1, join='inner')\n",
    "cons.to_csv(\"data/usa_blck_grp_cons.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization modeling\n",
    "\n",
    "We use an optimization model to construct the synthetic data by minimizing the difference between summarized information of the synthetic population and statistics in publicly available census tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gurobipy import Model, GRB, QuadExpr, quicksum\n",
    "import torch\n",
    "import csv\n",
    "\n",
    "# define all the input data for the model\n",
    "filename_cons = 'data/usa_blck_grp_cons.csv'\n",
    "cons = pd.read_csv(filename_cons)\n",
    "\n",
    "# set up parameters\n",
    "n1, n2, n3, n4, n5 = 3, 3, 2, 7, 2\n",
    "N = n1 * n2 * n3 * n4 * n5         # number of attribute combinations: HHGQ (3) ∗ AGE (3) ∗ HISPANIC (2) ∗ RACE (7) ∗ SEX (2)\n",
    "\n",
    "with open('data/usa_blck_grp_obj.csv', 'w', newline='') as f1:\n",
    "    wr1 = csv.writer(f1)\n",
    "    wr1.writerow([\"GEOID10\", \"obj\"])\n",
    "\n",
    "    with open('data/usa_blck_grp_hist.csv', 'w', newline='') as f2:\n",
    "        wr2 = csv.writer(f2)\n",
    "        # set up column names\n",
    "        col_names = [\"GEOID10\"]\n",
    "        hist_names = np.empty((n1, n2, n3, n4, n5), dtype=\"U10\")\n",
    "        for k1 in range(n1):\n",
    "            for k2 in range(n2):\n",
    "                for k3 in range(n3):\n",
    "                    for k4 in range(n4):\n",
    "                        for k5 in range(n5):\n",
    "                            hist_names[k1, k2, k3, k4, k5] = str(k1).zfill(2) + str(k2).zfill(2) + str(k3).zfill(2) + str(k4).zfill(2) + str(k5).zfill(2)\n",
    "        col_names.extend(hist_names.flatten())\n",
    "        wr2.writerow(col_names)\n",
    "\n",
    "        for idx, row in cons.iterrows():\n",
    "            GEOID10 = row[\"GEOID10\"]\n",
    "\n",
    "            A = torch.tensor(range(N))\n",
    "            A = A.reshape([n1, n2, n3, n4, n5])\n",
    "\n",
    "            # initialize model\n",
    "            m = Model('td')\n",
    "            m.Params.LogToConsole = 0\n",
    "\n",
    "            # add objective function\n",
    "            obj = QuadExpr()\n",
    "\n",
    "            # add variables and constraints\n",
    "            h = {}      ## detailed histogram (decision vairable)\n",
    "            for i in range(N):\n",
    "                h[i] = m.addVar(obj=0, vtype=GRB.INTEGER, lb=0, ub=row[\"H7V001\"], name=\"h_%d\"%(i))\n",
    "            m.update()\n",
    "\n",
    "            ## P1: TOTAL POPULATION\n",
    "            q0 = cons.loc[:, cons.columns.str.startswith(\"H7V\")].to_numpy()\n",
    "            res0, col_idx = {}, 0\n",
    "            hist_idx = torch.flatten(A[:, :, :, :, :]).tolist()\n",
    "            res0[col_idx] = m.addVar(obj=0, vtype=GRB.INTEGER, name=\"res0_%d\"%(col_idx))\n",
    "            obj += res0[col_idx] * res0[col_idx]\n",
    "            m.addConstr(res0[col_idx] == q0[idx, col_idx] - quicksum(h[i] for i in hist_idx))\n",
    "            m.update()\n",
    "\n",
    "            ## P5: HISPANIC OR LATINO ORIGIN BY RACE\n",
    "            q1 = cons.loc[:, cons.columns.str.startswith(\"H7Z\")].to_numpy()\n",
    "            res1, col_idx = {}, 0\n",
    "            for x in range(n3):  # hispanic\n",
    "                for y in range(n4):  # race \n",
    "                    hist_idx = torch.flatten(A[:, :, x, y, :]).tolist()\n",
    "                    res1[col_idx] = m.addVar(obj=0, vtype=GRB.INTEGER, name=\"res1_%d\"%(col_idx))\n",
    "                    obj += res1[col_idx] * res1[col_idx]\n",
    "                    m.addConstr(res1[col_idx] == q1[idx, col_idx] - quicksum(h[i] for i in hist_idx))\n",
    "                    m.update()\n",
    "                    col_idx += 1\n",
    "\n",
    "            ## P43: GROUP QUARTERS POPULATION BY SEX BY AGE BY GROUP QUARTERS TYPE\n",
    "            q2 = cons.loc[:, cons.columns.str.startswith(\"H8\")].to_numpy()\n",
    "            res2, col_idx = {}, 0     \n",
    "            for x in range(n5):  # sex\n",
    "                for y in range(n2):  # age\n",
    "                    for z in range(1, n1):  # hhgq\n",
    "                        hist_idx = torch.flatten(A[z, y, :, :, x]).tolist()\n",
    "                        res2[col_idx] = m.addVar(obj=0, vtype=GRB.INTEGER, name=\"res2_%d\"%(col_idx))\n",
    "                        obj += res2[col_idx] * res2[col_idx]\n",
    "                        m.addConstr(res2[col_idx] == q2[idx, col_idx] - quicksum(h[i] for i in hist_idx))\n",
    "                        m.update()\n",
    "                        col_idx += 1 \n",
    "\n",
    "            ## P12A-G: SEX BY AGE BY RACE\n",
    "            q3 = cons.loc[:, cons.columns.str.startswith(\"H9\")].to_numpy()\n",
    "            res3, col_idx = {}, 0   \n",
    "            for x in range(n4):  # race\n",
    "                for y in range(n5):  # sex\n",
    "                    for z in range(n2):  # age\n",
    "                        hist_idx = torch.flatten(A[:, z, :, x, y]).tolist()\n",
    "                        res3[col_idx] = m.addVar(obj=0, vtype=GRB.INTEGER, name=\"res3_%d\"%(col_idx))\n",
    "                        obj += res3[col_idx] * res3[col_idx]\n",
    "                        m.addConstr(res3[col_idx] == q3[idx, col_idx] - quicksum(h[i] for i in hist_idx))\n",
    "                        m.update()\n",
    "                        col_idx += 1\n",
    "\n",
    "            ## P12H: SEX BY AGE BY RACE (Hispanic or Latino)\n",
    "            q4 = cons.loc[:, cons.columns.str.startswith(\"H10\")].to_numpy()\n",
    "            res4, col_idx = {}, 0   \n",
    "            for x in range(n5):  # sex\n",
    "                for y in range(n2):  # age\n",
    "                    hist_idx = torch.flatten(A[:, y, 1, :, x]).tolist()\n",
    "                    res4[col_idx] = m.addVar(obj=0, vtype=GRB.INTEGER, name=\"res4_%d\"%(col_idx))\n",
    "                    obj += res4[col_idx] * res4[col_idx]\n",
    "                    m.addConstr(res4[col_idx] == q4[idx, col_idx] - quicksum(h[i] for i in hist_idx))\n",
    "                    m.update()\n",
    "                    col_idx += 1           \n",
    "\n",
    "            ## P12I: SEX BY AGE BY RACE (White Alone, Not Hispanic or Latino)\n",
    "            q5 = cons.loc[:, cons.columns.str.startswith(\"H11\")].to_numpy()\n",
    "            res5, col_idx = {}, 0   \n",
    "            for x in range(n5):  # sex\n",
    "                for y in range(n2):  # age\n",
    "                    hist_idx = torch.flatten(A[:, y, 0, 0, x]).tolist()\n",
    "                    res5[col_idx] = m.addVar(obj=0, vtype=GRB.INTEGER, name=\"res5_%d\"%(col_idx))\n",
    "                    obj += res5[col_idx] * res5[col_idx]\n",
    "                    m.addConstr(res5[col_idx] == q5[idx, col_idx] - quicksum(h[i] for i in hist_idx))\n",
    "                    m.update()\n",
    "                    col_idx += 1 \n",
    "\n",
    "            m.setObjective(obj, GRB.MINIMIZE)\n",
    "            m.optimize()\n",
    "\n",
    "            # write histogram values\n",
    "            hist_values = [GEOID10]\n",
    "            var_values = [int(var.X) for var in m.getVars() if 'h' == str(var.VarName[0])]\n",
    "            hist_values.extend(var_values)\n",
    "            wr2.writerow(hist_values)\n",
    "\n",
    "            # write objective values\n",
    "            obj = m.getObjective().getValue()\n",
    "            wr1.writerow([GEOID10, obj])\n",
    "            print(idx, obj)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert a matrix into a list of individuals\n",
    "\n",
    "We list all individuals in the individual-level data matrix as a collection of individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename_hist = 'data/usa_blck_grp_hist.csv'\n",
    "hist = pd.read_csv(filename_hist)\n",
    "hist[\"GEOID10\"] = hist[\"GEOID10\"].astype(str).str.zfill(12)\n",
    "\n",
    "cols = hist.columns[1:]\n",
    "with open('data/usa_microdata_all.csv', 'w', newline='') as fw:\n",
    "    fw.write(\"STATEA,COUNTYA,TRACTA,BLKGRPA,HTYPE,AGE,ETHN,RACE,SEX\\n\")\n",
    "\n",
    "    for index, row in hist.iterrows():\n",
    "        bg_id = row[\"GEOID10\"]\n",
    "        print(index)\n",
    "        tract_id, county_id, state_id = bg_id[:11], bg_id[:5], bg_id[:2]\n",
    "        for col in cols:\n",
    "            cnt = int(row[col])\n",
    "            if cnt != 0:\n",
    "                ht, va, e, r, s = int(col[0:2]) + 1, int(col[2:4]) + 1, int(col[4:6]) + 1, int(col[6:8]) + 1, int(col[8:10]) + 1\n",
    "                for i in range(cnt): \n",
    "                    fw.write(state_id + ',' + county_id + ',' + tract_id + ',' + bg_id + ',' + str(ht) + ',' + str(va) + ',' + str(e) + ',' + str(r) + ',' + str(s) + '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract data for each state and territory\n",
    "\n",
    "We extract the synthetic data for each state and territory in the United States."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename_fips = 'data/state_fips.txt'\n",
    "fips = pd.read_csv(filename_fips, delimiter='|')\n",
    "\n",
    "filename_data = 'data/usa_microdata_all.csv'\n",
    "data = pd.read_csv(filename_data)\n",
    "states = data['STATEA'].unique()\n",
    "for i in states:\n",
    "    new = data[data['STATEA'] == i]\n",
    "    name = fips[fips['STATE'] == i]['STUSAB'].values[0] + '_microdata.csv'\n",
    "    new.to_csv('data/microdata_by_state/' + name, index=False)\n",
    "    print(name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a008679cbd088a4c3afe869b0ba3c9ba83365f015c3b8b31efa42d9566d180f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
